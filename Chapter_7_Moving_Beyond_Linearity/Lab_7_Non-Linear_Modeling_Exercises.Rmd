---
title: "Lab 7 Non-Linear Modeling Exercises"
author: "Evan Woods"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.asp = 0.618)
knitr::opts_chunk$set(out.width = "70%")
knitr::opts_chunk$set(fig.align = "center")
knitr::opts_chunk$set(
  comment = ""
)
```

```{r message=FALSE, include=FALSE}
if(!require("MASS")) install.packages("MASS")
if(!require("ISLR2")) install.packages("ISLR2")
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("HH")) install.packages("HH") # VIF
if(!require("e1071")) install.packages("e1071") # naiveBayes
if(!require("class")) install.packages("class") # knn
if(!require("formulaic")) install.packages("formulaic")
if(!require("caTools")) install.packages("caTools")
if(!require("caret")) install.packages("caret")
if(!require("boot")) install.packages("boot")
if(!require("leaps")) install.packages("leaps") # regsubsets
if(!require("glmnet")) install.packages("glmnet") # Ridge and Lasso Regression
if(!require("pls")) install.packages("pls") # Partial Least Squares & Principal Component Regression
if(!require("splines")) install.packages("splines")
if(!require("gam")) install.packages("gam")
if(!require("akima")) install.packages("akima")


library(akima)
library(gam)
library(splines)
library(glmnet)
library(pls)
library(leaps)
library(formulaic)
library(class)
library(e1071)
library(HH)
library(MASS)
library(ISLR2)
library(tidyverse)
library(caTools)
library(caret)
library(boot)
```

```{r include=FALSE}
LoadLibraries <- function() {
if(!require("MASS")) install.packages("MASS")
if(!require("ISLR2")) install.packages("ISLR2")
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("HH")) install.packages("HH") # VIF
if(!require("e1071")) install.packages("e1071") # naiveBayes
if(!require("class")) install.packages("class") # knn
if(!require("formulaic")) install.packages("formulaic")
if(!require("caTools")) install.packages("caTools")
if(!require("caret")) install.packages("caret")

library(caret)
library(formulaic)
library(class)
library(e1071)
library(HH)
library(MASS)
library(ISLR2)
library(tidyverse)
library(caTools)
  print("Libraries have been loaded!")
}
```

```{r include=FALSE}
custom_darkblue = "#1A0875"
custom_lightblue = "#34ABEB"
custom_red = "#a60808"
```

```{r include=FALSE}
f_print <- function(string){
  cat(str_wrap(string = string, width = 80, indent = 0, exdent = 0, whitespace_only = TRUE))
}
```

```{r}
# Input: Dataframe, x (a numerical that is converted to a factor), y (double), title, x-axis title, y-axis title
# Output: Transparent violin plots overlayed onto colored yoxplots of y onto each x factor. Each boxplot is of a single x factor. 
create_custom_geom_box_grouped_by_x_factor <- function(df, x, y, title, x_title, y_title){
    ggplot(df, aes(as.factor(x), y)) +
      geom_boxplot(color = custom_darkblue, fill = custom_lightblue) +
      geom_violin(alpha = .1) + 
      theme_linedraw() +
      labs(title = title, x = x_title, y = y_title)  
}
```


```{r}
# Input: Dataframe, x, y, title of the plot, title of the x-axis, title of the y-axis
# Output: Scatterplot of x and y variables with correlation between the two on the grid & a smooth line of best fit to the data points. 
create_custom_geom_point <- function(df, x, y, title, x_title, y_title){
    correlation <- sprintf("r: %0.3f", cor(x,y))
    label <- df %>% summarise(x = max(x), y = max(y), label = correlation)
    ggplot(df, aes(x, y)) +
      geom_point(color = custom_darkblue) + 
      theme_linedraw() +
      geom_smooth(se = FALSE, color = custom_lightblue) +
      labs(title = title, x = x_title, y = y_title) + 
      geom_text(aes(label = label), data = label, vjust = "top", hjust = "right", color = "#a60808") 
}

```

```{r}
# ???
# Input: Dataframe, x, y, title of the plot, title of the x-axis, title of the y-axis
# Output: Scatterplot of x and y variables with correlation between the two on the grid & a smooth line of best fit to the data points. 
create_custom_geom_point_rss <- function(df, x, y, title, x_title, y_title){
    correlation <- sprintf("r: %0.3f", cor(x,y))
    label <- df %>% summarise(x = max(x), y = max(y), label = correlation)
    ggplot(df, aes(x, y)) +
      geom_point(color = custom_darkblue) + 
      theme_linedraw() +
      geom_smooth(se = FALSE, color = custom_lightblue) +
      labs(title = title, x = x_title, y = y_title) + 
      geom_text(aes(label = label), data = label, vjust = "top", hjust = "right", color = "#a60808") 
}

```


```{r}
# Input: 
    # df: dataframe containing x and y values to be plotted. 
    # plot_types: indicator (TRUE or NULL) that attributes of the the type of plot to create has been added to the dataframe before calling this function. All predictors must be included. The number of columns in the dataframe must equal the number of columns in the attribute that has been added. The name of the attribute must be "plot_types_when_on_x_axis". All variables will be plotted against another as in a pairs plot. Accepted values of the plot_types_when_on_x_axis include "point", and "box". Accepted values of plot_types_when_on_x_axis must be verbatim. When plot_types is NULL, the x axis will assume integers are categorical and convert them to factors in the custom plotting functions before creating box plots. 

# Example of adding attibutes to a dataframe:
# attr(auto_plot_formatted, "plot_types_when_on_x_axis") <- c("point", "box", "point", "point", "point", "point", "box", "box")
# attributes(auto_plot_formatted)

# Example df: $names
#  "mpg"          "cylinders"    "displacement" "horsepower"   "weight"       "acceleration" "year"         "origin"     

# Example attribute: $plot_types_when_on_x_axis
#  "point" "box"   "point" "point" "point" "point" "box"   "box" 
# In the example, when mpg is on the x axis, a scatter plot will be created. When origin is on the x axis, a box plot will be created. 


# Output: returns plots of all pairs of variables using ggplot. Plots are either of type scatter or box. 

create_all_custom_box_scatter_plots <- function(df, plot_types=NULL) {
    if(!is.null(plot_types)) {
    for (i in seq_along(df)) {
      current_x_axis_name <- names(df[i])
      current_x_axis <- df[[i]]
      current_plot_type <- attributes(df)$plot_types_when_on_x_axis
      # print(sprintf("current_x_axis_name: %s", current_x_axis_name))
      # print(sprintf("current_plot_type: %s", current_plot_type[[i]]))
      for (j in seq_along(df)) {
          
            current_y_axis_name <- names(df[j])
            
            if(identical(current_x_axis_name, current_y_axis_name)) {
              next
            }
            current_y_axis <- df[[j]]
          if (identical(current_plot_type[[i]], "point")) {
            if(identical(current_plot_type[[j]], "box")) {
              next
            # print("Dependent variable is a box plot & independent variable is a point plot.")
          } else {
              
              # print("Create Scatterplot 1")
              custom_plot <- create_custom_geom_point(
                df = df, 
                x = df[[i]], 
                y = df[[j]], 
                title = sprintf("%s vs. %s", current_x_axis_name, current_y_axis_name), 
                x_title = current_x_axis_name, 
                y_title = current_y_axis_name
              )
              # print(sprintf("j: %0.0f", j))
              # print(sprintf("current_plot_type[[j]]: %s", current_plot_type[[j]]))
              # print("create_custom_geom_point defined in 1")
            }
          } else if(identical(current_plot_type[[i]], "box")){
              # print("# Plot x as factor boxplot with double y 3.")
              custom_plot <- create_custom_geom_box_grouped_by_x_factor(
                df = df, 
                x = df[[i]], 
                y = df[[j]], 
                title = sprintf("%s vs. %s", current_x_axis_name, current_y_axis_name), 
                x_title = current_x_axis_name, 
                y_title = current_y_axis_name
              )
              # print(sprintf("j: %0.0f", j))
              # print(sprintf("current_plot_type[[j]]: %s", current_plot_type[[j]]))
              # print("create_custom_geom_box_grouped_by_x_factor defined in 3")
          } else {
            # print("Error in plot type. Plot type is neither scatter nor box.")
            next
          }
            print(custom_plot)
        }
    }
    } else {
    for (i in seq_along(df)) {
      current_x_axis_name <- names(df[i])
      current_x_axis <- df[[i]]
      # print(sprintf("current_x_axis_name: %s", current_x_axis_name))
      for (j in seq_along(df)) {
          
            current_y_axis_name <- names(df[j])
            
            if(identical(current_x_axis_name, current_y_axis_name)) {
              next
            }
            current_y_axis <- df[[j]]
          if (identical(typeof(df[[i]]), "double")) {
            if(identical(typeof(df[[j]]), "double")) {
              # print("Create Scatterplot 1")
              custom_plot <- create_custom_geom_point(
                df = df, 
                x = df[[i]], 
                y = df[[j]], 
                title = sprintf("%s vs. %s", current_x_axis_name, current_y_axis_name), 
                x_title = current_x_axis_name, 
                y_title = current_y_axis_name
              )
              # print("create_custom_geom_point defined in 1")
            } else if(identical(typeof(df[[j]]), "integer")) {
              # print("# Next: X is double, y is integer; Use y as x in boxplot. 2")
              next
            } else {
              # print("Error: X is a double. Y is neither a double nor an integer. Unhandled.")
            }
          } else if(identical(typeof(df[[i]]), "integer")){
            if(identical(typeof(df[[j]]), "integer")){
              # print("# Both x & y are integers. No custom plot exists yet")
              next
            } else if(identical(typeof(df[[j]]), "double")) {
              # print("# Plot x as factor boxplot with double y 3.")
              custom_plot <- create_custom_geom_box_grouped_by_x_factor(
                df = df, 
                x = df[[i]], 
                y = df[[j]], 
                title = sprintf("%s vs. %s", current_x_axis_name, current_y_axis_name), 
                x_title = current_x_axis_name, 
                y_title = current_y_axis_name
              )
              # print("create_custom_geom_box_grouped_by_x_factor defined in 3")
            } else {
              # print("Error: X is an integer. Y is neither a double nor an integer. Unhandled.")
            }
          } else {
            # print("X is neither integer nor double.")
          }
            print(custom_plot)
        }
    }
    }
}
```


## Applied

### Question 6:
In this exercise, you will further analyze the Wage data set considered throughout this chapter.

```{r message=FALSE}
set.seed(42)
attach(Wage)
```

* **Question 6-a**: Perform polynomial regression to predict wage using age. Use cross-validation to select the optimal degree _d_ for the polynomial. What degree was chosen, and how does this compare to the results of hypothesis testing using ANOVA? Make a plot of the resulting polynomial fit to the data. 
  * **Answer**:
```{r include=FALSE}
set.seed(42)

cv.error <- rep(0, 10)
for (i in 1:10) {
  glm.fit <- glm(wage ~ poly(age, i), data = Wage)
  cv.error[i] <- cv.glm(Wage, glm.fit)$delta[1]
}
```

```{r}
lm.fit1 <- lm(wage ~ poly(age, 1), data = Wage)
lm.fit2 <- lm(wage ~ poly(age, 2), data = Wage)
lm.fit3 <- lm(wage ~ poly(age, 3), data = Wage)
lm.fit4 <- lm(wage ~ poly(age, 4), data = Wage)
lm.fit5 <- lm(wage ~ poly(age, 5), data = Wage)
lm.fit6 <- lm(wage ~ poly(age, 6), data = Wage)
lm.fit7 <- lm(wage ~ poly(age, 7), data = Wage)
lm.fit8 <- lm(wage ~ poly(age, 8), data = Wage)
lm.fit9 <- lm(wage ~ poly(age, 9), data = Wage)
lm.fit10 <- lm(wage ~ poly(age, 10), data = Wage)
anova(lm.fit1, lm.fit2, lm.fit3, lm.fit4, lm.fit5, lm.fit6, lm.fit7, lm.fit8, lm.fit9, lm.fit10)
```

```{r}
f_print(sprintf("The model of degree %0.0f was chosen as the model with the lowest test error when tested using cross-validation.", which.min(cv.error)))
cat("\n")
f_print(sprintf("The model of degree 9 is a reasonable fit to the data when examined using the ANOVA test."))
```

* **Question 6-b**: Fit a step function to predict wage using age, and perform cross-validation to choose the optimal number of cuts. Make a plot of the fit obtained.
  * **Answer**:
```{r}
train <- sample(nrow(Wage)*.8)
test <- (-train)
```

```{r warning=FALSE}
k <- 10
folds <- sample(1:k, nrow(Wage), replace = TRUE)

error_matrix <- matrix(rep(0, 10),nrow=10,ncol=10)

for (i in 2:10){
  for (k in 1:10) {
    lm.cut_fit <- lm(wage ~ cut(age, i), data = Wage[folds != k, ])
    lm.cut_pred <- predict(lm.cut_fit, Wage)
    error_matrix[i,k] <- mean((Wage$wage - lm.cut_pred)[folds == k]^2)  
  }
}
clean_error_matrix <- error_matrix[-1, ]

average_test_mse_per_cut <- apply(clean_error_matrix, 1, mean)

lm.cut_fit <- lm(wage ~ cut(age, which.min(average_test_mse_per_cut)), data = Wage)
lm.cut_pred <- predict(lm.cut_fit, Wage)
```


```{r include=FALSE}
lm.cut_fit$xlevels[1]
breaks <- c(0, 26.9, 35.7, 44.6, 53.4, 62.3, 71.1, 80.1)
```


```{r warning=FALSE}
ggplot(Wage) +
  geom_point(aes(age, wage, color = wage)) +
  geom_line(aes(age, lm.cut_pred, color = lm.cut_pred), color = "white", size = 1) + 
  theme_dark() +
  scale_x_continuous(breaks = breaks) + 
  labs(title = "Step Function of Wage vs. Age", x = "Age", y = "Wage", subtitle = "Optimal ")
```

### Question 7:
The Wage data set contains a number of other features not explored
in this chapter, such as marital status (maritl), job class (jobclass),
and others. Explore the relationships between these other
predictors and wage, and use non-linear fitting techniques in order to
fit flexible models to the data. Create plots of the results obtained,
and write a summary of your findings.


```{r}
# maritl, jobclass, region
ggplot(Wage) + 
  geom_violin(aes(maritl, wage), fill = custom_lightblue) +
  geom_boxplot(aes(maritl, wage), color = custom_darkblue, fill = custom_lightblue, alpha = 0.3) +
  labs(title = "Marital Status vs. Wage", x = "Marital Status", y = "Wage ($1000s)")
```

```{r}
# maritl, jobclass, region
ggplot(Wage) + 
  geom_violin(aes(jobclass, wage), fill = custom_lightblue) +
  geom_boxplot(aes(jobclass, wage), color = custom_darkblue, fill = custom_lightblue, alpha = 0.3) +
  labs(title = "Wage vs. Job Class", x = "Job Class", y = "Wage ($1000s)")
```

```{r}
# Remove Widowed
wage_not_widowed <- Wage %>% filter(maritl != "3. Widowed") 
```

```{r}
levels(wage_not_widowed$maritl)
```


```{r}
gam.maritl <- gam(wage ~ maritl + jobclass + s(year, 5), data = wage_not_widowed)
par(mfrow = c(1, 1))
plot(gam.maritl, se = TRUE, col = "green")
```


```{r}
f_print(sprintf("There is a strong relationship between marital status & Information job class with respect to higher wages. Those that have never been married have the lowest wages whereas those that have been divorced or separated are associated with wages that are higher than those that have never been married but lower than those that have been married. There is a positive trend with increasing years with respect to wage."))
```

### Question 8:
Fit the non-linear models investigated in this chapter to the
Auto data set. Is there evidence for non-linear relationships in this
data set? Create informative plots to justify your answer.

```{r message=FALSE}
auto <- na.omit(Auto)
attach(Auto)
```

```{r}
head(Auto)
```

```{r}
auto_plot_formatted <- auto %>% select(everything(), -name)
```


```{r}
# auto
attr(auto_plot_formatted, "plot_types_when_on_x_axis") <- c("point", "box", "point", "point", "point", "point", "box", "box")
# attributes(auto_plot_formatted)
```

```{r warning=FALSE, message=FALSE}
create_all_custom_box_scatter_plots(auto_plot_formatted, plot_types = TRUE)
```


```{r warning=FALSE, message=FALSE}
lm.mpg_displacement_natural_spline.fit <- lm(mpg ~ ns(displacement, df = 6), data = auto)
lm.mpg_displacement_natural_spline.pred <- predict(lm.mpg_displacement_natural_spline.fit, auto)

lm.mpg_displacement_regression_spline.fit <- lm(mpg ~ bs(displacement, degree = 6), data = Wage)
lm.mpg_displacement_regression_spline.pred <- predict(lm.mpg_displacement_regression_spline.fit, auto)

ggplot() + 
  geom_point(aes(mpg, displacement), color = custom_lightblue) +
  geom_smooth(aes(lm.mpg_displacement_natural_spline.pred, displacement), color = custom_darkblue) +
  geom_smooth(aes(lm.mpg_displacement_regression_spline.pred, displacement), color = custom_red) +
  labs(title = "Splines of MPG vs. Displacement", x = "Miles Per Gallon", y = "Displacement", subtitle = "Natural Spline Prediction: Dark Blue\nRegression Spline Prediction: Red") +
  theme_grey()
```
```{r warning=FALSE}
lm.mpg_displacement_smooth_spline.fit <- smooth.spline(mpg, displacement, cv = TRUE)
```


```{r warning=FALSE}
# xlim = range(displacement)
plot(mpg, displacement, cex = .5, col = "darkgrey", main = "Smooth Spline of MPG vs. Displacement", xlab = "Miles Per Gallon", ylab = "Displacement")
lines(lm.mpg_displacement_smooth_spline.fit, col = "blue")
```

```{r warning=FALSE}
dof <- 3

lm.mpg_acceleration_natural_spline.fit <- lm(mpg ~ ns(acceleration, dof), data = Wage)
lm.mpg_acceleration_natural_spline.pred <- predict(lm.mpg_acceleration_natural_spline.fit, auto)

lm.mpg_acceleration_regression_spline.fit <- lm(mpg ~ bs(acceleration, df = dof), data = Wage)
lm.mpg_acceleration_regression_spline.pred <- predict(lm.mpg_acceleration_regression_spline.fit, auto)

ggplot() + 
  geom_point(aes(acceleration, mpg), color = custom_lightblue) +
  geom_line(aes(acceleration, lm.mpg_acceleration_regression_spline.pred), color = custom_red) +
  geom_line(aes(acceleration, lm.mpg_acceleration_natural_spline.pred), color = custom_darkblue) +
  labs(title = "Splines of MPG vs. Displacement", x = "Acceleration", y = "Miles Per Gallon", subtitle = "Natural Spline Prediction: Dark Blue\nRegression Spline Prediction: Red\n") +
  theme_grey()
```

```{r}
acceleration_limits <- range(acceleration)
acceleration.grid <- seq(acceleration_limits[1], acceleration_limits[2])

lo.mpg_acceleration_local_regression_spline.fit <- loess(mpg ~ acceleration, span = 0.2, data = auto)

plot(acceleration, mpg, xlim = acceleration_limits, cex = .05, col = "darkgrey", main = "Local Regression of Mpg vs. Acceleration", xlab = "Acceleration", ylab = "Miles Per Gallon")
lines(acceleration.grid, predict(lo.mpg_acceleration_local_regression_spline.fit, data.frame(acceleration = acceleration.grid)), col = "blue")
```

### Question 9:
This question uses the variables dis (the weighted mean of distances
to five Boston employment centers) and nox (nitrogen oxides concen-
tration in parts per 10 million) from the Boston data. We will treat
dis as the predictor and nox as the response.

```{r warning=FALSE, message=FALSE}
boston <- na.omit(Boston)
attach(boston)
```


* **Question 9-a**: Use the poly() function to fit a cubic polynomial regression to
predict nox using dis. Report the regression output, and plot
the resulting data and polynomial fits.
  * **Answer**:
```{r}
lm.fit9a <- lm(nox ~ poly(dis, 4))
summary(lm.fit9a)
lm.fit9a.pred <- predict(lm.fit9a, boston)

ggplot() + 
  geom_line(aes(dis, lm.fit9a.pred), color = custom_lightblue, size = 2) + 
  geom_point(aes(dis, nox), color = custom_darkblue) +
  labs(title = "NOx Concentration vs. Mean Distance to Employment Centers", x = "Weighted Mean of Distances to 5 Boston Employment Centers", y = "Nitrogen Oxides Concentration (Parts Per 10 Million)")
```

* **Question 9-b**: Plot the polynomial fits for a range of different polynomial
degrees (say, from 1 to 10), and report the associated residual
sum of squares.
  * **Answer**:
  
```{r}
RSS <- sprintf("RSS:\nHighest Degree of Polynomial:")
label <- boston %>% summarise(x = max(dis), y = max(nox), label = RSS)
label
```
  
  
```{r}
# Input: Dataframe, x, y, title of the plot, title of the x-axis, title of the y-axis
# Output: Scatterplot of x and y variables with correlation between the two on the grid & a smooth line of best fit to the data points. 
create_custom_geom_point_rss <- function(df, x, y, title, x_title, y_title, pred){
    RSS <- sprintf("RSS: %0.3f\nHighest Degree of Polynomial: %0.0f", sum((nox - pred)^2), i)
    label <- df %>% summarise(x = max(x), y = max(y), label = RSS)
    ggplot(df, aes(x, y)) +
      geom_point(color = custom_darkblue) + 
      theme_linedraw() +
      geom_line(aes(dis, pred), color = custom_lightblue, size = 1.5) +
      labs(title = title, x = x_title, y = y_title) + 
      geom_text(aes(label = label), data = label, vjust = "top", hjust = "right", color = "#a60808") 
}



rss <- c(integer(0))
for(i in 1:10) {
  lm.fit <- lm(nox ~ poly(dis, i))
  lm.pred <- predict(lm.fit, boston)
  rss[i] <- sum((nox - lm.pred)^2)
  print(create_custom_geom_point_rss(boston, dis, nox, "Polynomial of NOx Vs. Distance to Employment Centers", "Weighted Mean of Distances to 5 Boston Employment Centers", "Nitrogen Oxides Concentration (Parts Per 10 Million)", lm.pred))
}
```

* **Question 9-c**: Perform cross-validation or another approach to select the opti-
mal degree for the polynomial, and explain your results.
  * **Answer**:

```{r}
train <- sample(nrow(boston) * .8)

mse <- c(integer(10))
for (i in 1:10) {
# i <- 1
lm.fit <- lm(nox ~ poly(dis, i), data = boston, subset = train)
lm.pred <- predict(lm.fit, boston)
mse[i] <- mean((nox - lm.pred)[-train]^2)
}
```

```{r}
  f_print(sprintf("A training and testing validation set was used to identify the optimal value of the highest degree of the polynomial used to pred nox regressed onto weighted mean distance to 5 boston employment centers. The optimal value of the degree of polynomial which creates the lowest mse is %0.0f with a test mse value of %0.3f. This is supported by the graph Polynomial of NOx Vs. Distance to Employment Centers where the highest degree of the polynomial is 2. It is observable in the remaining graphs that degrees above 2 have high variance and fit too closely to the data. And the resulting decrease in variance is not outweighed by the increase in bias gained from using the linear model of degree 1. ", which.min(mse), mse[which.min(mse)]))
```
* **Question 9-d**:Use the bs() function to fit a regression spline to predict nox
using dis. Report the output for the fit using four degrees of
freedom. How did you choose the knots? Plot the resulting fit
  * **Answer**:
```{r}
lm.fit <- lm(nox ~ bs(dis, df = 4))
lm.pred <- predict(lm.fit, boston)
summary(lm.fit)
f_print(sprintf("The output for the fit using four degrees of freedom is observable from the summary above. The knots where selected automatically using the selected 4 degrees of freedom."))
```

```{r message=FALSE}
ggplot() + 
  geom_point(aes(dis, nox), color = custom_darkblue) + 
  geom_line(aes(dis, lm.pred), color = custom_lightblue, size = 1.5) +
  labs(title = "Polynomial of NOx Vs. Distance to Employment Centers", x = "Weighted Mean of Distances to 5 Boston Employment Centers", y = "Nitrogen Oxides Concentration (Parts Per 10 Million)", subtitle = "Highest Degree of Polynomial: 4") 
```


* **Question 9-e**: Now fit a regression spline for a range of degrees of freedom, and
plot the resulting fits and report the resulting RSS. Describe the
results obtained.
  * **Answer**:
```{r}
max_dis <- max(dis)
max_nox <- max(nox)

for (i in 3:10) {
  lm.fit <- lm(nox ~ bs(dis, df = i))
  lm.pred <- predict(lm.fit, boston)
  rss <- sum((boston$nox - lm.pred)^2)
  poly_degree <- sprintf("RSS: %0.3f\nDegrees of Freedom: %0.0f", rss, i)
  label <- boston %>% summarise(x = max_dis, y = max_nox, label = poly_degree)
  regression_spline <- ggplot() + 
    geom_point(aes(dis, nox), color = custom_darkblue) + 
    geom_line(aes(dis, lm.pred), color = custom_lightblue, size = 1.5) +
    labs(title = "Regression Spline of NOx Vs. Distance to Employment Centers", x = "Weighted Mean of Distances to 5 Boston Employment Centers", y = "Nitrogen Oxides Concentration (Parts Per 10 Million)", subtitle = "Varying Degrees of Freedom") +
  geom_text(aes(max_dis, max_nox, label = label), data = label, vjust = "top", hjust = "right", color = "#a60808")
  print(regression_spline)
}
```
* **Question 9-f**: Perform cross-validation or another approach in order to select
the best degrees of freedom for a regression spline on this data.
Describe your results.
  * **Answer**:
```{r}
train <- sample(nrow(boston)*.8)
test <- (-train)
mse <- integer(length = 7)
for (i in 3:10) {
  lm.fit <- lm(nox ~ bs(dis, i), data = boston, subset = train)
  lm.pred <- predict(lm.fit, boston[test, ])
  mse[i - 2] = mean((nox[test] - lm.pred)^2)
}

f_print(sprintf("The degree of freedom that promotes the minimum mean squared error for the created regression spline is: %0.0f degrees of freedom. The calculated test mse is: %0.7f.", which.min(mse) + 2,  mse[which.min(mse)]))
```



