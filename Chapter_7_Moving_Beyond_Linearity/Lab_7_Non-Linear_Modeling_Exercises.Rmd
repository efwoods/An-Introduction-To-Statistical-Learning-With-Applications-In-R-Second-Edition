---
title: "Lab 7 Non-Linear Modeling Exercises"
author: "Evan Woods"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.asp = 0.618)
knitr::opts_chunk$set(out.width = "70%")
knitr::opts_chunk$set(fig.align = "center")
knitr::opts_chunk$set(
  comment = ""
)
```

```{r message=FALSE, include=FALSE}
if(!require("MASS")) install.packages("MASS")
if(!require("ISLR2")) install.packages("ISLR2")
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("HH")) install.packages("HH") # VIF
if(!require("e1071")) install.packages("e1071") # naiveBayes
if(!require("class")) install.packages("class") # knn
if(!require("formulaic")) install.packages("formulaic")
if(!require("caTools")) install.packages("caTools")
if(!require("caret")) install.packages("caret")
if(!require("boot")) install.packages("boot")
if(!require("leaps")) install.packages("leaps") # regsubsets
if(!require("glmnet")) install.packages("glmnet") # Ridge and Lasso Regression
if(!require("pls")) install.packages("pls") # Partial Least Squares & Principal Component Regression
if(!require("splines")) install.packages("splines")
if(!require("gam")) install.packages("gam")
if(!require("akima")) install.packages("akima")


library(akima)
library(gam)
library(splines)
library(glmnet)
library(pls)
library(leaps)
library(formulaic)
library(class)
library(e1071)
library(HH)
library(MASS)
library(ISLR2)
library(tidyverse)
library(caTools)
library(caret)
library(boot)
```

```{r include=FALSE}
LoadLibraries <- function() {
if(!require("MASS")) install.packages("MASS")
if(!require("ISLR2")) install.packages("ISLR2")
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("HH")) install.packages("HH") # VIF
if(!require("e1071")) install.packages("e1071") # naiveBayes
if(!require("class")) install.packages("class") # knn
if(!require("formulaic")) install.packages("formulaic")
if(!require("caTools")) install.packages("caTools")
if(!require("caret")) install.packages("caret")

library(caret)
library(formulaic)
library(class)
library(e1071)
library(HH)
library(MASS)
library(ISLR2)
library(tidyverse)
library(caTools)
  print("Libraries have been loaded!")
}
```

```{r include=FALSE}
custom_darkblue = "#1A0875"
custom_lightblue = "#34ABEB"
custom_red = "#a60808"
```

```{r include=FALSE}
f_print <- function(string){
  cat(str_wrap(string = string, width = 80, indent = 0, exdent = 0, whitespace_only = TRUE))
}
```

## Applied

### Question 6:
In this exercise, you will further analyze the Wage data set considered throughout this chapter.

```{r message=FALSE}
set.seed(42)
attach(Wage)
```

* **Question 6-a**: Perform polynomial regression to predict wage using age. Use cross-validation to select the optimal degree _d_ for the polynomial. What degree was chosen, and how does this compare to the results of hypothesis testing using ANOVA? Make a plot of the resulting polynomial fit to the data. 
  * **Answer**:
```{r}
set.seed(42)
cv.error <- rep(0, 10)
for (i in 1:10) {
  glm.fit <- glm(wage ~ poly(age, i), data = Wage)
  cv.error[i] <- cv.glm(Wage, glm.fit)$delta[1]
}
```

```{r}
lm.fit1 <- lm(wage ~ poly(age, 1), data = Wage)
lm.fit2 <- lm(wage ~ poly(age, 2), data = Wage)
lm.fit3 <- lm(wage ~ poly(age, 3), data = Wage)
lm.fit4 <- lm(wage ~ poly(age, 4), data = Wage)
lm.fit5 <- lm(wage ~ poly(age, 5), data = Wage)
lm.fit6 <- lm(wage ~ poly(age, 6), data = Wage)
lm.fit7 <- lm(wage ~ poly(age, 7), data = Wage)
lm.fit8 <- lm(wage ~ poly(age, 8), data = Wage)
lm.fit9 <- lm(wage ~ poly(age, 9), data = Wage)
lm.fit10 <- lm(wage ~ poly(age, 10), data = Wage)
anova(lm.fit1, lm.fit2, lm.fit3, lm.fit4, lm.fit5, lm.fit6, lm.fit7, lm.fit8, lm.fit9, lm.fit10)
```

```{r}
f_print(sprintf("The model of degree %0.0f was chosen as the model with the lowest test error when tested using cross-validation.", which.min(cv.error)))
cat("\n")
f_print(sprintf("The model of degree 9 is a reasonable fit to the data when examined using the ANOVA test."))
```

* **Question 6-b**: Fit a step function to predict wage using age, and perform cross-validation to choose the optimal number of cuts. Make a plot of the fit obtained.
  * **Answer**:
```{r}
train <- sample(nrow(Wage)*.8)
test <- (-train)
```

```{r warning=FALSE}
k <- 10
folds <- sample(1:k, nrow(Wage), replace = TRUE)

error_matrix <- matrix(rep(0, 10),nrow=10,ncol=10)

for (i in 2:10){
  for (k in 1:10) {
    lm.cut_fit <- lm(wage ~ cut(age, i), data = Wage[folds != k, ])
    lm.cut_pred <- predict(lm.cut_fit, Wage)
    error_matrix[i,k] <- mean((Wage$wage - lm.cut_pred)[folds == k]^2)  
  }
}
clean_error_matrix <- error_matrix[-1, ]

average_test_mse_per_cut <- apply(clean_error_matrix, 1, mean)

lm.cut_fit <- lm(wage ~ cut(age, which.min(average_test_mse_per_cut)), data = Wage)
lm.cut_pred <- predict(lm.cut_fit, Wage)
```


```{r include=FALSE}
lm.cut_fit$xlevels[1]
breaks <- c(0, 26.9, 35.7, 44.6, 53.4, 62.3, 71.1, 80.1)
```


```{r warning=FALSE}
ggplot(Wage) +
  geom_point(aes(age, wage, color = wage)) +
  geom_line(aes(age, lm.cut_pred, color = lm.cut_pred), color = "white", size = 1) + 
  theme_dark() +
  scale_x_continuous(breaks = breaks) + 
  labs(title = "Step Function of Wage vs. Age", x = "Age", y = "Wage")
```

