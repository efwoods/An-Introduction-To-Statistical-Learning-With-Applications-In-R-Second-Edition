---
title: "Lab 6 Linear Models and Regularization Methods"
author: "Evan Woods"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.asp = 0.618)
knitr::opts_chunk$set(out.width = "70%")
knitr::opts_chunk$set(fig.align = "center")
knitr::opts_chunk$set(
  comment = ""
)
```

```{r message=FALSE, include=FALSE}
if(!require("MASS")) install.packages("MASS")
if(!require("ISLR2")) install.packages("ISLR2")
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("HH")) install.packages("HH") # VIF
if(!require("e1071")) install.packages("e1071") # naiveBayes
if(!require("class")) install.packages("class") # knn
if(!require("formulaic")) install.packages("formulaic")
if(!require("caTools")) install.packages("caTools")
if(!require("caret")) install.packages("caret")
if(!require("boot")) install.packages("boot")
if(!require("leaps")) install.packages("leaps") # regsubsets; best subset selection
if(!require("glmnet")) install.packages("glmnet")
if(!require("pls")) install.packages("pls") # Partial Least Squares Regression & Principal Components Regression

library(pls)
library(glmnet)
library(leaps)
library(formulaic)
library(class)
library(e1071)
library(HH)
library(MASS)
library(ISLR2)
library(tidyverse)
library(caTools)
library(caret)
library(boot)
```

```{r include=FALSE}
LoadLibraries <- function() {
if(!require("MASS")) install.packages("MASS")
if(!require("ISLR2")) install.packages("ISLR2")
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("HH")) install.packages("HH") # VIF
if(!require("e1071")) install.packages("e1071") # naiveBayes
if(!require("class")) install.packages("class") # knn
if(!require("formulaic")) install.packages("formulaic")
if(!require("caTools")) install.packages("caTools")
if(!require("caret")) install.packages("caret")

library(caret)
library(formulaic)
library(class)
library(e1071)
library(HH)
library(MASS)
library(ISLR2)
library(tidyverse)
library(caTools)
  print("Libraries have been loaded!")
}
```

```{r include=FALSE}
custom_darkblue = "#1A0875"
custom_lightblue = "#34ABEB"
custom_red = "#a60808"
```


```{r include=FALSE}
f_print <- function(string){
  cat(str_wrap(string = string, width = 80, indent = 0, exdent = 0, whitespace_only = TRUE))
}
```


## Subset Selection Methods
### Best Subset Selection
```{r include=FALSE}
library(ISLR2)
# View(Hitters)
```


```{r include=FALSE}
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
```

```{r}
library(leaps)
regfit.full <- regsubsets(Salary ~ ., Hitters)
summary(regfit.full)
```

```{r}
# length(Hitters)
regfit.full <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)
names(reg.summary)
```
```{r}
reg.summary$rsq
```

```{r}
par(mfrow = c(2,2))
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of Variables", ylab = "Adj. RSq", type = "l")

which.max(reg.summary$adjr2)
points(11, reg.summary$adjr2[11], col = "red", cex = 2)
```

```{r}
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
which.min(reg.summary$cp)
points(10, reg.summary$cp[10], col = "red", cex = 2, pch = 20)
which.min(reg.summary$bic)
plot(reg.summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
points(6, reg.summary$bic[6], col = "red", cex = 2, pch = 20)
```

```{r}
plot(regfit.full, scale = "r2")
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
plot(regfit.full, scale = "bic")
```

### Forward and Backward Stepwise Selection
```{r}
regfit.fwd <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "forward")
regfit.bwd <- regsubsets(Salary ~ ., data = Hitters, method = "backward", nvmax  = 19)
summary(regfit.bwd)
```

```{r}
coef(regfit.full, 7)
coef(regfit.fwd, 7)
coef(regfit.bwd, 7)
```
## Model Selection with Cross Validation and Validation Set
### Best Subset Selection using a Validation Set
```{r}
set.seed(1)
train <- sample(c(TRUE, FALSE), nrow(Hitters), replace = TRUE)
test <- (!train)
```

```{r}
regfit.best <- regsubsets(Salary ~ ., data = Hitters[train,], nvmax = 19)
```

```{r}
test.mat <- model.matrix(Salary ~ ., data = Hitters[test, ]) # model.matrix transforms a data.frame into a matrix
```

```{r}
val.errors <- rep(NA, 19)
for (i in 1:19) {
  coefi <- coef(regfit.best, id = i)
  pred <- test.mat[, names(coefi)] %*% coefi
  val.errors[i] <- mean((Hitters$Salary[test] - pred)^2)
}

val.errors
which.min(val.errors)
coef(regfit.best, 7)
```

```{r}
predict.regsubsets <- function(object, newdata, id, ...) {
  form <- as.formula(object$call[[2]])
  mat <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  xvars <- names(coefi)
  mat[, xvars] %*% coefi
}
```

```{r}
regfit.best <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
coef(regfit.best, 7)
```


K-Fold Cross-Validation Selection
```{r}
k <- 10
n <- nrow(Hitters)
set.seed(1)
folds <- sample(rep(1:k, length = n)) # grouping each observation into k groups
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL, paste(1:19)))
```

```{r}
for (j in 1:k) {
  best.fit <- regsubsets(Salary ~ .,
                         data = Hitters[folds != j, ], nvmax = 19) # Training on all but k.
  for (i in 1:19) {
    pred <- predict(best.fit, Hitters[folds == j, ], id = i) # Predict using k. This will use the custom predict function above. Best i variable model.
    cv.errors[j, i] <-
      mean((Hitters$Salary[folds == j] - pred) ^2) # Mean Square Error of each predictor within a k fold.
  }
}
```

```{r}
mean.cv.errors <- apply(cv.errors, 2, mean) # Identify the k which has the lowest mean test error
mean.cv.errors
par(mfrow = c(1,1))
plot(mean.cv.errors, type = "b")
```

```{r}
Hitters
```


```{r}
# Best Subset Selection of the full dataset to obtain the 10 variable model.
reg.best <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
coef(reg.best, 10)
```

## Ridge Regression and the Lasso
```{r}
x <- model.matrix(Salary ~ ., data = Hitters)[, -1] # -1 removes the intercept
y <- Hitters$Salary
```

### Ridge Regression
```{r}
grid <- 10^seq(10, -2, length = 100)
```


```{r}
dim(coef(ridge.mod))
```

```{r}
ridge.mod$lambda[50] # Lambda = 11,498; the 50th Lambda
coef(ridge.mod)[,50] # Coefficients @ Lambda = 11,498; intercepts are rows, the columns are coefficients.
sqrt(sum(coef(ridge.mod)[-1, 50]^2)) # L2 norm
```

```{r}
ridge.mod$lambda[60]
coef(ridge.mod)[, 60]
sqrt(sum(coef(ridge.mod)[-1, 60]^2))
```

```{r}
predict(ridge.mod, s = 50, type = "coefficients")[1:20, ] # Selecting the value of lambda = 50. This is a prediction using the full dataset.
```

```{r}
# Creating a ridge regression prediction using a validation set.
set.seed(1)
train <- sample(1:nrow(x), nrow(x) / 2)
test <- (-train)
y.test <- y[test]
```

```{r}
ridge.mod <- glmnet(x[train, ], y[train], alpha = 0, lambda = grid, thresh = 1e-12)
ridge.pred <- predict(ridge.mod, s = 4, newx = x[test, ]) # use newx to select the test set when making predictions.
mean((ridge.pred - y.test)^2) # The intercept is included when calculating the MSE.
```

```{r}
# Computing the test error if the model only used the intercept. (The Null Model)
mean((mean(y[train]) - y.test)^2)
```

```{r}
# Computing the test error if the model only used the intercept by reducing the predictors in a ridge regression using a very large value of lambda.
ridge.pred <- predict(ridge.mod, s = 1e10, newx = x[test, ])
mean((ridge.pred - y.test)^2)
```

```{r}
# Least Squares Regression: Î» = 0
ridge.pred <- predict(ridge.mod, s = 0, newx = x[test, ], exact = TRUE, x = x[train, ], y = y[train])
mean((ridge.pred - y.test)^2)
```


```{r}
# Comparing linear model least squares regression to a least squares regression using a ridge regression.
lm(y ~ x, subset = train)
predict(ridge.mod, s = 0, exact = TRUE, type = "coefficients", x = x[train, ], y = y[train])[1:20, ] # Exact = True: Choose precise values for the coefficients. The difference between lm and glmnet with respect to the decimal place is an estimation using glmnet.
```

```{r}
# Using cross-validation to select the optimal value of lambda to minimize test error.
set.seed(1)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 0)
plot(cv.out)
min_lambda <- cv.out$lambda.min
min_lambda
```

```{r}
# Test error using the optimal value of lambda
ridge.pred <- predict(ridge.mod, s = 326, newx = x[test, ])
mean((ridge.pred - y[test])^2)
```


```{r}
# Fitting the entire dataset using the optimal value of lambda.
out <- glmnet(x, y, alpha = 0)
out.pred <- predict(out, s = min_lambda, type = "coefficients")[1:20, ]
out.pred
```

```{r}
# Create a validation set
set.seed(1)
train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y.test <- y[test]
```

```{r}
set.seed(1)
# Cross validation 
ridge_regression_model <- cv.glmnet(x[train, ], y[train], alpha = 0)
ridge_regression_model$lambda.min
ridge_regression_model.pred <- predict(ridge_regression_model, s = ridge_regression_model$lambda.min, newx = x[test, ])
mean((ridge_regression_model.pred - y[test])^2)

ridge_regression <- glmnet(x, y, alpha = 0)
ridge_regression.pred <- predict(ridge_regression, s = ridge_regression_model$lambda.min, type = "coefficients")[1:20, ]
ridge_regression.pred
```


# Lasso Regression
```{r}
set.seed(1)
lasso.mod <- glmnet(x[train, ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)

```
```{r}
set.seed(1)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
plot(cv.out)
cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s = cv.out$lambda.min, newx = x[test, ])
mean((lasso.pred - y.test)^2)
```


```{r}
 out <- glmnet(x, y, lambda = grid, alpha = 1)
lasso.coef <- predict(out, s = cv.out$lambda.min, type = "coefficients")[1:20, ]
lasso.coef
```

## PCR & PLS Regression
### Principal Components Regression
```{r}
library(pls)
set.seed(2)
```

```{r}
pcr.fit <- pcr(Salary ~ ., data = Hitters, scale = TRUE, validation = "CV") # Setting scale = TRUE will standardize each predictor. validation = "CV" means using a ten-fold cross-validation for each number of principle components.
summary(pcr.fit)
```


```{r}
# Printing the cross validation scores
validationplot(pcr.fit, val.type = "MSEP")
```

```{r}
set.seed(1)
pcr.fit <- pcr(Salary ~ ., data = Hitters, subset = train, scale = TRUE, validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
```

```{r}
# Calculating the means squared error after making predictions using the ideal number of components.
pcr.pred <- predict(pcr.fit, x[test, ], ncomp = 5)
mean((pcr.pred - y.test)^2)
```

```{r}
# Fitting a Principal Component Regression to all the data
pcr.fit <- pcr(y ~ x, scale = TRUE, ncomp = 5)
summary(pcr.fit)
```

### Partial Least Squares
```{r}
set.seed(1)
pls.fit <- plsr(Salary ~ ., data = Hitters, validation  = "CV", scale = TRUE)
summary(pls.fit)
validationplot(pls.fit, val.type = "MSEP")
```


```{r}
pls.pred <- predict(pls.fit, x[test, ], ncomp = 1)
mean((pls.pred - y.test)^2)
```
```{r}
plt.fit <- plsr(Salary ~ ., data = Hitters, scale = TRUE, ncomp = 1)
summary(pls.fit)
```

